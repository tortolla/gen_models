{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4cb96",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from src.model import load_clip\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "#загружаем модель\n",
    "model, processor = load_clip(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046fb6b",
   "metadata": {},
   "source": [
    "Простой пример инференса: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f3264",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "\n",
    "image_paths = sorted(list(DATA_DIR.glob(\"*.jpg\")) + list(DATA_DIR.glob(\"*.png\")))\n",
    "print(\"Found images:\")\n",
    "for p in image_paths:\n",
    "    print(\" -\", p)\n",
    "\n",
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b69c9d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"a magnifying glass\",\n",
    "    \"a cute dog\",\n",
    "    \"a smiling person\",\n",
    "]\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f840b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    inputs = processor(\n",
    "        text=texts,\n",
    "        images=img,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits_per_image = outputs.logits_per_image  \n",
    "    logits = logits_per_image[0]              \n",
    "\n",
    "    probs = softmax(logits, dim=0)  # shape [num_texts]\n",
    "\n",
    "    print(f\"\\nResults for {img_path.name}:\")\n",
    "    for text, p in zip(texts, probs):\n",
    "        print(f\"  {text:25s} {float(p):.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
