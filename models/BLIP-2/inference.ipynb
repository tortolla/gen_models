{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772d88d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from src.model import load_blip2, generate_answer\n",
    "\n",
    "# 1. Загружаем модель\n",
    "model, processor, device = load_blip2()\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 2. Пути к картинкам\n",
    "data_dir = Path(\"data\")\n",
    "image_paths = {\n",
    "    \"cat\": data_dir / \"cat.jpg\",\n",
    "    \"dog\": data_dir / \"dog.jpg\",\n",
    "    \"girl_cat\": data_dir / \"girl_cat.jpg\",\n",
    "}\n",
    "\n",
    "for name, p in image_paths.items():\n",
    "    print(name, \"->\", p, \"| exists:\", p.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff19d2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def blip2_caption(image_path, prompt: str = \"Describe this image in detail.\"):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    display(img.resize((384, 384)))\n",
    "\n",
    "    text = generate_answer(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        image=img,\n",
    "        prompt=prompt,\n",
    "        device=device,\n",
    "        max_new_tokens=64,\n",
    "    )\n",
    "    print(\"\\nBLIP-2:\", text)\n",
    "\n",
    "\n",
    "# Примеры\n",
    "blip2_caption(image_paths[\"cat\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb89c2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "blip2_caption(image_paths[\"dog\"])\n",
    "blip2_caption(\n",
    "    image_paths[\"girl_cat\"],\n",
    "    prompt=\"Describe the relationship between the person and the cat.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb45beb9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def blip2_qa(image_path, question: str):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    display(img.resize((384, 384)))\n",
    "\n",
    "    prompt = f\"Question: {question} Answer:\"\n",
    "    answer = generate_answer(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        image=img,\n",
    "        prompt=prompt,\n",
    "        device=device,\n",
    "        max_new_tokens=32,\n",
    "    )\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(\"A:\", answer)\n",
    "\n",
    "\n",
    "# Примеры вопросов\n",
    "blip2_qa(image_paths[\"dog\"], \"What breed is this dog?\")\n",
    "blip2_qa(image_paths[\"girl_cat\"], \"Where is the cat and what is the person doing?\")\n",
    "blip2_qa(image_paths[\"cat\"], \"Is this photo taken indoors or outdoors?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de896a84",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def chat_step(image, history: str, user_message: str, max_new_tokens: int = 64):\n",
    "    \"\"\"\n",
    "    history: строка с предыдущим диалогом \"User: ...\\nAssistant: ...\\n...\"\n",
    "    user_message: новый вопрос/реплика пользователя\n",
    "    \"\"\"\n",
    "    if history:\n",
    "        prompt = (\n",
    "            \"You are a helpful assistant that reasons about the image and the conversation.\\n\"\n",
    "            \"Image is given once; then follow the dialog.\\n\\n\"\n",
    "            + history\n",
    "            + f\"\\nUser: {user_message}\\nAssistant:\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = (\n",
    "            \"You are a helpful assistant that describes and reasons about the image.\\n\"\n",
    "            f\"User: {user_message}\\nAssistant:\"\n",
    "        )\n",
    "\n",
    "    answer = generate_answer(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        image=image,\n",
    "        prompt=prompt,\n",
    "        device=device,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "    )\n",
    "\n",
    "    new_history = history + f\"\\nUser: {user_message}\\nAssistant: {answer}\"\n",
    "    return answer, new_history\n",
    "\n",
    "\n",
    "# Инициализируем чат\n",
    "img_chat = Image.open(image_paths[\"girl_cat\"]).convert(\"RGB\")\n",
    "display(img_chat.resize((384, 384)))\n",
    "\n",
    "history = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df81d44",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def chat_step(image, history: str, user_message: str, max_new_tokens: int = 64):\n",
    "    \"\"\"\n",
    "    history: строка с предыдущим диалогом \"User: ...\\nAssistant: ...\\n...\"\n",
    "    user_message: новый вопрос/реплика пользователя\n",
    "    \"\"\"\n",
    "    if history:\n",
    "        prompt = (\n",
    "            \"You are a helpful assistant that reasons about the image and the conversation.\\n\"\n",
    "            \"Image is given once; then follow the dialog.\\n\\n\"\n",
    "            + history\n",
    "            + f\"\\nUser: {user_message}\\nAssistant:\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = (\n",
    "            \"You are a helpful assistant that describes and reasons about the image.\\n\"\n",
    "            f\"User: {user_message}\\nAssistant:\"\n",
    "        )\n",
    "\n",
    "    answer = generate_answer(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        image=image,\n",
    "        prompt=prompt,\n",
    "        device=device,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "    )\n",
    "\n",
    "    new_history = history + f\"\\nUser: {user_message}\\nAssistant: {answer}\"\n",
    "    return answer, new_history\n",
    "\n",
    "\n",
    "# Инициализируем чат\n",
    "img_chat = Image.open(image_paths[\"girl_cat\"]).convert(\"RGB\")\n",
    "display(img_chat.resize((384, 384)))\n",
    "\n",
    "history = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2e005",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Шаг 1\n",
    "answer, history = chat_step(\n",
    "    img_chat,\n",
    "    history=history,\n",
    "    user_message=\"Describe this photo briefly.\",\n",
    ")\n",
    "print(\"Assistant:\", answer)\n",
    "\n",
    "# Шаг 2\n",
    "answer, history = chat_step(\n",
    "    img_chat,\n",
    "    history=history,\n",
    "    user_message=\"What emotions do you think the person might be feeling?\",\n",
    ")\n",
    "print(\"\\nAssistant:\", answer)\n",
    "\n",
    "# Шаг 3\n",
    "answer, history = chat_step(\n",
    "    img_chat,\n",
    "    history=history,\n",
    "    user_message=\"Invent a short caption for Instagram for this photo.\",\n",
    ")\n",
    "print(\"\\nAssistant:\", answer)\n",
    "\n",
    "# Посмотреть, что накопилось в истории\n",
    "print(\"\\n--- FULL HISTORY ---\")\n",
    "print(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b9b58",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img_chat = Image.open(image_paths[\"girl_cat\"]).convert(\"RGB\")\n",
    "display(img_chat.resize((384, 384)))\n",
    "\n",
    "history = \"\"\n",
    "\n",
    "while True:\n",
    "    q = input(\"\\nYou: \")\n",
    "    if not q.strip():\n",
    "        break\n",
    "    answer, history = chat_step(img_chat, history, q)\n",
    "    print(\"Assistant:\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
