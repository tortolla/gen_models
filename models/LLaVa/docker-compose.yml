services:
  blip:
    build: .
    container_name: llama-demo
    ports:
      - "8888:8888"      # Jupyter из Dockerfile
    volumes:
      - .:/app
    gpus: all         # монтируем код с хоста внутрь контейнера
       # использовать все доступные GPU
    # если на сервере ещё старый docker-compose и ругается на gpus,
    # можно будет потом заменить на
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]



