{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18adc7ce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "from PIL import Image\n",
    "import torch \n",
    "from scr.model import load_llava, llava ask\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, processor = load_llava(device)\n",
    "\n",
    "results = demo_llava_on_image(model, processor, \"example.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95b501",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import LlavaForConditionalGeneration, AutoProcessor\n",
    "from PIL import Image\n",
    "import torch\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def load_llava(device: str | torch.device = \"cpu\"):\n",
    "    model_name = \"llava-hf/llava-1.5-7b-hf\"\n",
    "\n",
    "    if device == \"cpu\":\n",
    "        torch_dtype = torch.float32\n",
    "        device_map = None\n",
    "    else:\n",
    "        torch_dtype = torch.float16\n",
    "        device_map = \"auto\"\n",
    "\n",
    "    model = LlavaForConditionalGeneration.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device_map=device_map,\n",
    "    )\n",
    "    processor = AutoProcessor.from_pretrained(model_name)\n",
    "\n",
    "    if device == \"cpu\":\n",
    "        model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    return model, processor\n",
    "\n",
    "\n",
    "def generate_llava_answer(\n",
    "    model,\n",
    "    processor,\n",
    "    image: Image.Image,\n",
    "    prompt: str,\n",
    "    device: str | torch.device = \"cpu\",\n",
    "    max_new_tokens: int = 128,\n",
    "):\n",
    "    \"\"\"\n",
    "    Аналог твоего generate_answer, но заточен под формат LLaVA-1.5:\n",
    "    USER: <image>\\n<prompt> ASSISTANT:\n",
    "    \"\"\"\n",
    "    full_prompt = f\"USER: <image>\\n{prompt} ASSISTANT:\"\n",
    "\n",
    "    inputs = processor(\n",
    "        text=full_prompt,\n",
    "        images=image,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "        )\n",
    "\n",
    "    # LLaVA возвращает только ответ ассистента\n",
    "    answer = processor.batch_decode(output_ids, skip_special_tokens=True)[0]\n",
    "    return answer.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81647547",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def llava_caption(image_path: str):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    display(img.resize((384, 384)))\n",
    "\n",
    "    prompt = (\n",
    "        \"Опиши изображение подробно: какие объекты видны, что они делают, \"\n",
    "        \"как они расположены относительно друг друга, какой общий контекст сцены.\"\n",
    "    )\n",
    "\n",
    "    answer = generate_llava_answer(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        image=img,\n",
    "        prompt=prompt,\n",
    "        device=device,\n",
    "        max_new_tokens=128,\n",
    "    )\n",
    "\n",
    "    print(\"\\nCAPTION (LLaVA):\")\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d7b8e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def llava_qa(image_path: str, question: str, max_new_tokens: int = 64):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    display(img.resize((384, 384)))\n",
    "\n",
    "    prompt = f\"Вопрос: {question}\\nОтветь максимально чётко и по существу.\"\n",
    "\n",
    "    answer = generate_llava_answer(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        image=img,\n",
    "        prompt=prompt,\n",
    "        device=device,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "    )\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(\"A:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf8b29d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def llava_qa(image_path: str, question: str, max_new_tokens: int = 64):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    display(img.resize((384, 384)))\n",
    "\n",
    "    prompt = f\"Вопрос: {question}\\nОтветь максимально чётко и по существу.\"\n",
    "\n",
    "    answer = generate_llava_answer(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        image=img,\n",
    "        prompt=prompt,\n",
    "        device=device,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "    )\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(\"A:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85e9f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "llava_caption(image_paths[\"dog\"])\n",
    "\n",
    "llava_qa(image_paths[\"dog\"], \"Какая это порода собаки и по каким признакам ты так думаешь?\")\n",
    "llava_qa(image_paths[\"girl_cat\"], \"Где находится кошка и что делает человек?\")\n",
    "llava_qa(image_paths[\"cat\"], \"Это помещение внутри или снаружи? Обоснуй свой ответ.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b601f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def llava_reasoning_demo(image_path: str, max_new_tokens: int = 128):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    display(img.resize((384, 384)))\n",
    "\n",
    "    tasks = {\n",
    "        \"rich_caption\": (\n",
    "            \"Опиши сцену так, будто объясняешь её незрячему человеку. \"\n",
    "            \"Не просто перечисли объекты, а расскажи, что они делают, \"\n",
    "            \"как взаимодействуют и какой общий настрой у сцены.\"\n",
    "        ),\n",
    "        \"before_after\": (\n",
    "            \"Предположи, что могло происходить за несколько секунд до этого момента \"\n",
    "            \"и что с высокой вероятностью произойдет через минуту. Объясни свою логику.\"\n",
    "        ),\n",
    "        \"objects_and_layout\": (\n",
    "            \"Перечисли основные объекты на изображении и опиши их примерное расположение \"\n",
    "            \"словами (слева, справа, на переднем плане, на заднем плане, в центре и т.д.).\"\n",
    "        ),\n",
    "        \"counting_and_explanation\": (\n",
    "            \"Сколько основных объектов одного типа ты видишь (например, людей, животных, машин)? \"\n",
    "            \"Опиши, как ты считал и почему уверен в этом числе.\"\n",
    "        ),\n",
    "        \"emotions_and_relations\": (\n",
    "            \"Опиши вероятные эмоции людей или животных на фото и отношения между ними \"\n",
    "            \"(доверие, игра, забота, осторожность и т.д.). Объясни, какие визуальные \"\n",
    "            \"подсказки к этому приводят.\"\n",
    "        ),\n",
    "        \"ocr_and_reasoning\": (\n",
    "            \"Если на изображении есть текст, постарайся переписать его и объяснить, \"\n",
    "            \"какую роль этот текст играет в контексте сцены.\"\n",
    "        ),\n",
    "        \"story_mode\": (\n",
    "            \"Придумай короткую историю (3-5 предложений), которая могла бы соответствовать \"\n",
    "            \"этой фотографии. Используй детали с картинки и не выдумывай того, чего явно нет.\"\n",
    "        ),\n",
    "        \"instagram_captions\": (\n",
    "            \"Придумай три варианта подписи для Instagram к этому фото: \"\n",
    "            \"1) шутливую, 2) тёплую/милую, 3) более философскую.\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, prompt in tasks.items():\n",
    "        print(f\"\\n================= {name} =================\")\n",
    "        answer = generate_llava_answer(\n",
    "            model=model,\n",
    "            processor=processor,\n",
    "            image=img,\n",
    "            prompt=prompt,\n",
    "            device=device,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "        print(answer)\n",
    "        results[name] = answer\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff92da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Например, показать, что LLaVA «умнее» BLIP именно по рассуждению\n",
    "llava_reasoning_demo(image_paths[\"girl_cat\"])\n",
    "llava_reasoning_demo(image_paths[\"dog\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9703ad12",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def llava_chat_step(\n",
    "    image: Image.Image,\n",
    "    history: str,\n",
    "    user_message: str,\n",
    "    max_new_tokens: int = 128,\n",
    "):\n",
    "    \"\"\"\n",
    "    history — строка вида:\n",
    "    'USER: ... ASSISTANT: ...</s>USER: ... ASSISTANT: ...'\n",
    "\n",
    "    Мы просто добавляем ещё один USER/ASSISTANT и скармливаем LLaVA.\n",
    "    \"\"\"\n",
    "    if history:\n",
    "        prompt = (\n",
    "            \"История диалога:\\n\"\n",
    "            f\"{history}\\n\\n\"\n",
    "            \"Сейчас продолжи диалог, учитывая картинку и контекст выше.\\n\\n\"\n",
    "            f\"USER: {user_message}\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = (\n",
    "            \"Ты — полезный ассистент, который рассуждает по изображению и ведёт диалог с пользователем.\\n\"\n",
    "            f\"USER: {user_message}\"\n",
    "        )\n",
    "\n",
    "    # Оборачиваем всё в формат LLaVA-1.5\n",
    "    full_prompt = (\n",
    "        \"USER: <image>\\n\"\n",
    "        + prompt\n",
    "        + \" ASSISTANT:\"\n",
    "    )\n",
    "\n",
    "    answer = generate_llava_answer(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        image=image,\n",
    "        prompt=full_prompt,\n",
    "        device=device,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "    )\n",
    "\n",
    "    # обновляем историю в формате LLaVA\n",
    "    new_history = history + f\"\\nUSER: {user_message}\\nASSISTANT: {answer}</s>\"\n",
    "    return answer, new_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d7811",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img_chat = Image.open(image_paths[\"girl_cat\"]).convert(\"RGB\")\n",
    "display(img_chat.resize((384, 384)))\n",
    "\n",
    "history = \"\"\n",
    "\n",
    "# Шаг 1\n",
    "answer, history = llava_chat_step(\n",
    "    img_chat,\n",
    "    history=history,\n",
    "    user_message=\"Опиши это фото кратко.\",\n",
    ")\n",
    "print(\"Assistant:\", answer)\n",
    "\n",
    "# Шаг 2\n",
    "answer, history = llava_chat_step(\n",
    "    img_chat,\n",
    "    history=history,\n",
    "    user_message=\"Какие эмоции, по-твоему, испытывает человек?\",\n",
    ")\n",
    "print(\"\\nAssistant:\", answer)\n",
    "\n",
    "# Шаг 3\n",
    "answer, history = llava_chat_step(\n",
    "    img_chat,\n",
    "    history=history,\n",
    "    user_message=\"Придумай короткую подпись для Instagram для этого фото.\",\n",
    ")\n",
    "print(\"\\nAssistant:\", answer)\n",
    "\n",
    "print(\"\\n--- FULL HISTORY ---\")\n",
    "print(history)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
